{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "968e7594-39c0-4e5f-9e3c-43f022dfd6ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "#mandatory imports\n",
    "import time\n",
    "from Bio import Entrez\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import spacy\n",
    "import urllib.request, urllib.error, urllib.parse\n",
    "import json\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "13c8df16-9197-41d2-9e4a-62e8795c3c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "## Thesaurus declaration\n",
    "thesaurus = {\n",
    "    \"Ivermectin\" : [\"IVM\", \"Ivermectin\", \"Avermectin\", \"avermectin\", \"ivermectin\", \"stromectol\", \"Stromectol\", \"Eqvalan\", \"Ivomec\", \"Mectizan\", \"Dihydroavermectin\", \"MK 933\", \"MK-933\", \"MK933\", \"C48H74O14\", \"IV\", \"IVM-654\", \"IVR-25\", \"IV-104\", \"IVE-11\", \"IVER-15\"],\n",
    "    \"GABA\" : [\"GABA\", \"GABAergic\", \"gamma-aminobutyric acid\"],\n",
    "    \"Zebrafish\" : [\"Zebrafish\", \"Danio rerio\"],\n",
    "    \"COVID-19\" : [\"COVID-19\", \"COVID\", \"SARS-CoV-2\"],\n",
    "    \"Glutamate\" : [\"Glutamate\", \"glutamate\",\"Glu\", \"L-(+)-glutamate\",\"L-Glu\", \"L-Glutamate\", \"L-glutamate\", \"L glutamate\", \"L glutamate\"]\n",
    "}\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d0758957-98e0-47b0-bfa7-cc356b6cab88",
   "metadata": {},
   "outputs": [],
   "source": [
    "def global_db_search(query_list, genes_list=[]):\n",
    "\n",
    "    if len(genes_list) != 0:\n",
    "        for i in query_list:\n",
    "            for j in genes_list:\n",
    "                query = i + j + \"[tiab]\"\n",
    "\n",
    "                handle = Entrez.egquery(term=query)\n",
    "                record = Entrez.read(handle)\n",
    "                df = pd.DataFrame(record[\"eGQueryResult\"]).head(2)\n",
    "                df[\"Query\"] = query\n",
    "                append_data(df, 'global_query_res.csv', False)\n",
    "                time.sleep(0.34)\n",
    "    else:\n",
    "        for i in query_list:\n",
    "            handle = Entrez.egquery(term=i)\n",
    "            record = Entrez.read(handle)\n",
    "            df = pd.DataFrame(record[\"eGQueryResult\"]).head(2)\n",
    "            df[\"Query\"] = i\n",
    "            append_data(df, 'global_query_res.csv', False)\n",
    "            time.sleep(0.34)\n",
    "    return\n",
    "\n",
    "\n",
    "## Function for reading in the df \"summary\" results\n",
    "def read_in_results(file_name):\n",
    "\n",
    "    # The converters are there so that each list is NOT inside a string\n",
    "    res_df = pd.read_csv(file_name,  converters={\"MainID_List\": lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"),\n",
    "                                                    \"P_Dates\": lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"),\n",
    "                                                    \"P_Years\": lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"),\n",
    "                                                    \"LinkedID_List\": lambda x: x.strip(\"[]\").replace(\"'\", \"\").split(\", \"),\n",
    "                                                    \"Query_Count\": int})\n",
    "    return res_df\n",
    "\n",
    "\n",
    "def esummary_info(in_webenv_key, in_query_key, db_name):\n",
    "\n",
    "    # Obtaining DocSums for a set of IDs that are stored on the Entrez History server.\n",
    "    handle = Entrez.esummary(db=db_name, webenv=in_webenv_key, query_key=in_query_key)\n",
    "    record = Entrez.read(handle)\n",
    "\n",
    "    publ_dates, publ_years = get_published_dates(record)\n",
    "\n",
    "    if db_name == \"pubmed\":\n",
    "        ids_list = get_pmcids(record)\n",
    "    else:\n",
    "        ids_list = get_pmids(record)\n",
    "\n",
    "    return publ_dates, publ_years, ids_list\n",
    "\n",
    "\n",
    "def get_published_dates(esummary_rec):\n",
    "\n",
    "    retr_dates = []\n",
    "    retr_years = []\n",
    "    check = True\n",
    "    i = 0\n",
    "    for article in esummary_rec:\n",
    "        # \"PubDate\" is often of the form: '2021 Nov 26'\n",
    "        retr_dates.append(article[\"PubDate\"])\n",
    "        date = article[\"PubDate\"].split()\n",
    "        while(i < 2):\n",
    "            if len(date[i]) == 4:\n",
    "                p_year = int(date[i])\n",
    "                i = 3\n",
    "            else:\n",
    "                i = i + 1\n",
    "        #p_year = int(article[\"PubDate\"].split()[0])\n",
    "        #p_year = int(article[\"P_Years\"].split()[0])\n",
    "        #changed from PubDate to P_Years because of error when changing search term\n",
    "        retr_years.append(p_year)\n",
    "\n",
    "    return retr_dates, retr_years\n",
    "\n",
    "\n",
    "def get_pmcids(esummary_rec):\n",
    "\n",
    "    pmcids_list = []\n",
    "    for i in esummary_rec:\n",
    "        # If \"pmc\" is there, then this article also has a PMCID (i.e., it's also found in the PubMed Central db)\n",
    "        if \"pmc\" in i[\"ArticleIds\"]:\n",
    "            pmcids_list.append(i[\"ArticleIds\"][\"pmc\"])\n",
    "        else:\n",
    "            pmcids_list.append(np.NaN)\n",
    "\n",
    "    return pmcids_list\n",
    "\n",
    "\n",
    "def get_pmids(esummary_rec):\n",
    "\n",
    "    pmids_list = []\n",
    "    for i in esummary_rec:\n",
    "        # '0' means that the article has no PMID (i.e., it's not found in the PubMed db)\n",
    "        if i[\"ArticleIds\"][\"pmid\"] == '0':\n",
    "            pmids_list.append(np.NaN)\n",
    "        else:\n",
    "            pmids_list.append(i[\"ArticleIds\"][\"pmid\"])\n",
    "\n",
    "    return pmids_list\n",
    "\n",
    "\n",
    "## Function that retrieves summary results from a given set of queries (which don't require a gene list)\n",
    "def get_query_info_no_genes(query_in, db_name):\n",
    "\n",
    "    # relevance: Records are sorted based on relevance to your search. (Relevance ranking)\n",
    "    search_results = Entrez.read(\n",
    "        Entrez.esearch(db=db_name, term=query_in, sort=\"relevance\", retmax=5000, usehistory=\"y\")\n",
    "        )\n",
    "\n",
    "    # NEED TO FIRST CHECK IF WE GOT ANY RESULTS FROM THAT QUERY\n",
    "    if len(search_results[\"IdList\"]) == 0:\n",
    "        print(\"No Results.\")\n",
    "        return\n",
    "    else:\n",
    "        # With search_results, we will use its WebEnv value and QueryKey value\n",
    "        p_dates, p_years, ids_list = esummary_info(search_results[\"WebEnv\"], search_results[\"QueryKey\"], db_name)\n",
    "\n",
    "        time.sleep(0.34)\n",
    "\n",
    "        return pd.DataFrame([[query_in, db_name, search_results['Count'], search_results['IdList'], p_dates, p_years, ids_list]],\n",
    "                                columns=['Query', 'Db_Name', 'Query_Count', 'MainID_List', 'P_Dates', 'P_Years', 'LinkedID_List'])\n",
    "\n",
    "\n",
    "## Function that retrieves summary results from a given set of queries (which requires a gene list)\n",
    "def get_query_info(query_in, genes, db_name):\n",
    "\n",
    "    gene_query = []\n",
    "    query = \"\"\n",
    "\n",
    "    for i in genes:\n",
    "        # Example of db_name values in this use case: \"pubmed\" or \"pmc\"\n",
    "        if db_name == \"pubmed\":\n",
    "            # PubMed's Search field tag: Title/Abstract [tiab]\n",
    "            query = query_in + i + \"[tiab]\"\n",
    "        else:\n",
    "            query = query_in + i\n",
    "\n",
    "        # relevance: Records are sorted based on relevance to your search. (Relevance ranking)\n",
    "        search_results = Entrez.read(\n",
    "            Entrez.esearch(db=db_name, term=query, sort=\"relevance\", retmax=5000, usehistory=\"y\")\n",
    "            )\n",
    "     \n",
    "        # NEED TO FIRST CHECK IF WE GOT ANY RESULTS FROM THAT QUERY\n",
    "        if len(search_results[\"IdList\"]) == 0:\n",
    "            continue\n",
    "\n",
    "        # With search_results, we will use its WebEnv value and QueryKey value\n",
    "        p_dates, p_years, ids_list = esummary_info(search_results[\"WebEnv\"], search_results[\"QueryKey\"], db_name)\n",
    "       \n",
    "        gene_query.append([query, db_name, search_results['Count'], search_results['IdList'], p_dates, p_years, ids_list])\n",
    "        time.sleep(0.34)\n",
    "          \n",
    "    return pd.DataFrame(gene_query, columns=['Query', 'Db_Name', 'Query_Count', 'MainID_List', 'P_Dates', 'P_Years', 'LinkedID_List'])\n",
    "\n",
    "\n",
    "## Function for obtaining citation counts for the set of IDs found in the \"summary\" df\n",
    "def cited_cnt_table(df_summary, db_name):\n",
    "\n",
    "    elink_data = []\n",
    "    link_name = \"\"\n",
    "\n",
    "    if db_name == \"pubmed\":\n",
    "        link_name = \"pubmed_pubmed_citedin\"\n",
    "    else:\n",
    "        link_name = \"pmc_pmc_citedby\"  # \"pmc\" is the other db_name in this use case\n",
    "\n",
    "    for i in range(0, len(df_summary)):\n",
    "\n",
    "        query_term = df_summary.iloc[i][\"Query\"]\n",
    "\n",
    "        for id_num in df_summary.iloc[i][\"MainID_List\"]:\n",
    "\n",
    "            record = Entrez.read(Entrez.elink(id=id_num, dbfrom=db_name, db=db_name, linkname=link_name))\n",
    "         \n",
    "            if len(record[0][\"LinkSetDb\"]) != 0:\n",
    "                cited_counts = len(record[0][\"LinkSetDb\"][0][\"Link\"])\n",
    "            else:\n",
    "                # 'LinkSetDb' key contains empty list when an article has no citation counts\n",
    "                cited_counts = 0\n",
    "            elink_data.append([query_term, db_name, id_num, cited_counts])\n",
    "\n",
    "            if (df_summary.iloc[i][\"MainID_List\"].index(id_num) + 1) % 3 == 0:\n",
    "                time.sleep(0.34)\n",
    "\n",
    "    return pd.DataFrame(elink_data, columns=[\"Query\", \"Db_Name\", \"Id_List\", \"Citation_Cnts\"]) \n",
    "\n",
    "\n",
    "## Function that returns the Top-k results (pass in k as an argument to the function, input by the user)\n",
    "def get_top_k(df, k_val):\n",
    "\n",
    "    q_top_k = []\n",
    "\n",
    "    for q in df[\"Query\"].unique():\n",
    "        matches_ids = []  # For each query version, these are the IDs meeting the criteria of having citation counts >= 25\n",
    "        counts = []\n",
    "        df_temp = df[df[\"Query\"] == q]\n",
    "\n",
    "        for i in range(0, len(df_temp)):\n",
    "            if df_temp.iloc[i][\"Citation_Cnts\"] >= 25:\n",
    "                matches_ids.append(int(df_temp.iloc[i][\"Id_List\"]))\n",
    "                counts.append(df_temp.iloc[i][\"Citation_Cnts\"])\n",
    "                if len(matches_ids) == k_val:\n",
    "                    break\n",
    "        if len(matches_ids) == 0:\n",
    "            continue\n",
    "        q_top_k.append([q, matches_ids, counts])\n",
    "\n",
    "    top_k_df = pd.DataFrame(q_top_k, columns=[\"Query\", \"Top_\"+str(k_val)+\"_Ids\", \"Citation_Cnts\"])\n",
    "\n",
    "    return top_k_df\n",
    "\n",
    "\n",
    "## Function that appends DataFrame rows to a CSV file\n",
    "def append_data(df, file_name, is_new_file):\n",
    "\n",
    "    if is_new_file:\n",
    "        # if True, then\n",
    "        df.to_csv(file_name, index=False)\n",
    "    else:\n",
    "        # False: This is an existing CSV file\n",
    "        df.to_csv(file_name, mode='a', index=False, header=False)\n",
    "\n",
    "    return"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b15ad664-00ed-45c2-b82d-6bdb63797f7c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# Load in the model for English\n",
    "nlp = spacy.load(\"en_core_web_sm\")\n",
    "# Can't retrieve XML if you don't have a query.\n",
    "query = \"GABA AND Glutamate\"\n",
    "Entrez.email = \"n01365801@unf.edu.com\"\n",
    "df_q_pubmed = get_query_info_no_genes(query, \"pubmed\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "8d0a4fb4-3e76-49d6-8137-e30c4b853bf1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Documentation for fetch_pubmed()\n",
    "\n",
    "This function's purpose is to use NCBI's E-Utils to get the body of articles, given an id.\n",
    "The E-Util used in E-Fetch.\n",
    "Future Work on this could be adjusting the argument, to allow for just a list of IDs, instead of a Pandas DataFrame slice.\n",
    "\n",
    "Arguments:\n",
    "    * ids: The IDs of articles from a Pandas DataFrame\n",
    "Return Value: A list of the records.\n",
    "\"\"\"\n",
    "def fetch_pubmed(ids): \n",
    "    records_pubmed = []\n",
    "    # Fetch all records pertaining to our queries.\n",
    "    for row in ids:\n",
    "        for uid in row:\n",
    "            handle = Entrez.efetch(db=\"pubmed\", id=uid, retmode=\"xml\")\n",
    "            record = Entrez.read(handle, validate=False)\n",
    "            records_pubmed.append(record)\n",
    "    # Be polite and flush/close the stream like a good programmer.\n",
    "    handle.close()\n",
    "    return records_pubmed\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "6f2a3a7c-60ce-4871-8fae-4aa2651ea715",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "records_pubmed = fetch_pubmed(df_q_pubmed['MainID_List'])\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "085aaa40-18e0-421b-9b36-cd3762e128b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "#print(records_pubmed[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bfcd7d35-d972-4502-8db5-6cbc884061da",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Documentation for invert_dict()\n",
    "\n",
    "This function's sole purpose is to invert a dictionary, so that the values of the old are the keys of the new,\n",
    "and the keys of the old are the values of the new, in list format.\n",
    "\n",
    "Arguments:\n",
    "    dictionary: The dictionary to be inverted.\n",
    "Return Value: The inverted dictionary following the above design.\n",
    "\"\"\"\n",
    "def invert_dict(dictionary):\n",
    "    dict_inverted = {} # output\n",
    "    for (k, v) in dictionary.items():\n",
    "        if v in dict_inverted.keys():\n",
    "            dict_inverted[v].append(k)\n",
    "        else:\n",
    "            dict_inverted[v] = [k]\n",
    "            \n",
    "    return dict_inverted\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "529df7e7-04f5-4f14-8c7e-d9162e97c46e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Documentation for find_comentions()\n",
    "\n",
    "Future Work for this function includes generalizing it to be able to handle both PubMed and PMC.\n",
    "This will likely require some work on reranking() below, as it only handles PubMed formatted XML,\n",
    "due to issues with PMC and Biopython present while writing this code.\n",
    "\n",
    "Arguments:\n",
    "    * thes: A dictionary containing the synonyms of query terms.\n",
    "    * doc: A SpaCy Doc object that contains the text we are looking at.\n",
    "Return Value: A tuple in the form of (sentences, proximity list)\n",
    "\"\"\"\n",
    "def find_comentions(thes, doc):\n",
    "    sentences = []\n",
    "    proximity_list = []\n",
    "    for sentence in doc.sents:\n",
    "        prev_term = \"\"\n",
    "        term_seen = False\n",
    "        first_i = 0\n",
    "        for word in sentence:\n",
    "            for term in thes.keys():\n",
    "                if term_seen:\n",
    "                    if (word.text in thes[term]) and (word.text not in thes[prev_term]):\n",
    "                        proximity_list.append(int(word.i - first_i))\n",
    "                        first_i = word.i\n",
    "                        prev_term = term\n",
    "                        sentences.append(str(sentence))\n",
    "                        break\n",
    "                elif (word.text in thes[term]):\n",
    "                    term_seen = True\n",
    "                    first_i = word.i\n",
    "                    prev_term = term\n",
    "                    break\n",
    "    \n",
    "    return (str(sentences), proximity_list)\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "27658a40-2d25-470b-9e63-befb4fab9b9a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Record indexed at 4838 improperly formatted.\n",
      "Num records proccessed: 5000\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "Documentation for reranking()\n",
    "\n",
    "This function will use find_comentions(), invert_dict(), and word_proximity() to create a general ranking of the articles.\n",
    "The articles will be identified by UID.\n",
    "\n",
    "Future additions to this reranking function include using Ms. Victoria's get_top_k() and cited_cnt_table() functions to add in the\n",
    "25 citation requirement for credibility. Other work includes breaking out some functionality into other functions in order to clean up the mess.\n",
    "\n",
    "Arguments:\n",
    "    * records: A list of XML Objects returned by E-Fetch.\n",
    "    * query_terms: A list of query_terms. These then get selected out of the Thesaurus.\n",
    "Return Value: The rankings for the records. Type is a Pandas DataFrame.\n",
    "\"\"\"\n",
    "### TODO: Break apart this function into smaller functions\n",
    "    # Namely, creation of combined_criteria, creation of top_15, and creation of DataFrame\n",
    "def reranking(records, query_terms):\n",
    "    # snippet from https://stackoverflow.com/questions/29216889/slicing-a-dictionary\n",
    "    # While in the answer, they add a check to make sure the key is in original dict\n",
    "    # (the thesaurus in this case), it is safe to assume that the key is in the dict,\n",
    "    # because the thesaurus should contain all possible terms.\n",
    "    inner_thesaurus = {k:thesaurus[k] for k in query_terms}\n",
    "\n",
    "    # DataFrame Data\n",
    "    pmids = []\n",
    "    titles = []\n",
    "    abstracts = []\n",
    "    relevancy_score = {}\n",
    "    comention_sentences = []\n",
    "    i = 0\n",
    "    j = 0\n",
    "    for record in records:\n",
    "        # Some records do not have an Abstract (???) so we need to check for an abstract\n",
    "        # TODO: Deal with the articles that don't have abstracts\n",
    "        try:\n",
    "            pmid = str(record['PubmedArticle'][0]['MedlineCitation']['PMID'])\n",
    "            article_keys = record['PubmedArticle'][0]['MedlineCitation']['Article'].keys()\n",
    "            if 'Abstract' in article_keys: # We have an Abstract\n",
    "                # TODO: Stop rewriting this indexing mess every time.\n",
    "                abstract_text = str(record['PubmedArticle'][0]['MedlineCitation']['Article']['Abstract']['AbstractText'])\n",
    "                # Process the abstract\n",
    "                doc = nlp(abstract_text)\n",
    "\n",
    "                (comention_sents, proximity_count) = find_comentions(doc=doc, thes=inner_thesaurus)\n",
    "\n",
    "                # DataFrame data collection\n",
    "                pmids.append(pmid)\n",
    "                titles.append(str(record['PubmedArticle'][0]['MedlineCitation']['Article']['ArticleTitle']))\n",
    "                abstracts.append(abstract_text)\n",
    "                comention_sentences.append(comention_sents)\n",
    "                if (len(proximity_count) != 0):\n",
    "                    relevancy_score[pmid] = sum([1/count for count in proximity_count])\n",
    "                else:\n",
    "                    relevancy_score[pmid] = 0\n",
    "            i = i + 1\n",
    "            j = j + 1\n",
    "        except:\n",
    "            i = i + 1\n",
    "            j = j + 1\n",
    "            print(\"Record indexed at \" + str(i) + \" improperly formatted.\")\n",
    "    print(\"Num records proccessed: \" + str(j))\n",
    "    # Relevancy score will be used to calculate the index.\n",
    "    prerankings = pd.DataFrame(data=[pmids, titles, abstracts, relevancy_score.values(), comention_sentences]).transpose()\n",
    "    prerankings.columns = [\"PMID\", \"Title\", \"Abstract\", \"Relevancy Score\", \"Comention Sentences\"]\n",
    "    \n",
    "    \n",
    "    #formatting for output\n",
    "    \n",
    "    \n",
    "    relevancy_score_inverted = invert_dict(relevancy_score)\n",
    "    # Gathering the top 15 abstracts based on the relevancy score.\n",
    "    # We conglomerate all of the scores into a single list, flatten it, and then simply slice out the first 15 elements.\n",
    "    top_15 = []\n",
    "    for i in sorted(relevancy_score_inverted.keys(), reverse=True):\n",
    "        top_15.append(relevancy_score_inverted[i])\n",
    "    # This list comprehension is flattening the list of lists produced by combined_criteria filtering.\n",
    "    top_15 = [x for xs in top_15 for x in xs]\n",
    "    top_15 = top_15[:15]\n",
    "    #prerankings.astype({'Comention Sentences': 'string'}).dtypes\n",
    "    prerankings[\"Comention Sentences\"] = prerankings[\"Comention Sentences\"].apply(lambda x: \"\".join(str(x)))\n",
    "    prerankings[\"Comention Sentences\"] = prerankings[\"Comention Sentences\"].apply(lambda x: str(x).strip(\"[]\"))\n",
    "    #prerankings[\"Title\"] = prerankings[\"Title\"].apply(lambda x: str(x).strip(\"[]\"))\n",
    "    \n",
    "    \n",
    "    # Now that we have the UIDs of our top 15, we can grab them\n",
    "    rankings = prerankings[prerankings[\"PMID\"].isin(top_15)].sort_values(by=\"Relevancy Score\", ascending=False).reset_index(drop=True)\n",
    "    \n",
    "    return rankings\n",
    "\n",
    "# FIXME: Do NOT hardcode the query_terms, pull them in from the query.\n",
    "rankings = reranking(records_pubmed, [\"GABA\",\"Glutamate\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "620907f5-4fb2-4a5b-a1e5-29913147c7a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "rankings\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "id": "e9ed846c-de2f-439e-a6d5-dec2fcd16319",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Done.\n"
     ]
    }
   ],
   "source": [
    "# CSV output\n",
    "rankings.to_csv(\"Glutamate and GABA3.csv\")\n",
    "print(\"Done.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8a8b451f-15d1-488a-82f0-b2ecc90c3428",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:DIS] *",
   "language": "python",
   "name": "conda-env-DIS-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
